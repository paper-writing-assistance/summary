element_idx,keywords,summarized_text
5,"translation, multiple, domains, image-to-image",StarGAN is a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model . This leads to the superior quality of translated images compared to existing models and the novel capability of translating an input image to any desired target domain .
7,"translation, image-to-image, gan","The task of image-to-image translation is to change a particular aspect of a given image to another, e.g., changing the facial expression of someone from smiling to frowning . This task has experienced significant improvements following the introduction of generative adversarial networks ."
8,"of, translate, value, age, image","Models learn to translate images from one domain to the other . We denote the terms attribute as a meaningful feature inherent in an image . For example, images of women can share same attribute value ."
12,"translation, multi-domain, rafd, celeba, image","CelebA dataset contains 40 labels related to facial attributes such as hair color, gender, and age . RaFD dataset has 8 labels for facial expressions such as 'happy' , 'angry' and 'sad' These settings enable us to perform more interesting tasks, namely multi-domain image"
13,"generated, translation, multi-domain, image","existing models are both inefficient and ineffective in such multi-domain image translation tasks . In order to learn all mappings between k domains, k generators have to be trained ."
14,"domain, multiple, information, domains","StarGAN is a novel and scalable approach capable of learning mappings . Our model takes in training data of multiple domains and learns the mappings between all available domains using only a single generator . Instead of learning a fixed translation, our generator takes in as inputs both image and domain information ."
20,"translation, multiple, domain, network, labels, multi-, adversarial, image","We propose StarGAN, a novel generative adversarial network that learns the mappings between multiple domains using only a single generator and a discriminator . We provide both qualitative and quantitative results on facial attribute transfer and facial expression synthesis tasks ."
22,"gan, translation, generation, image","Generative adversarial networks have shown remarkable results in various computer vision tasks such as image generation , image translation , super-resolution imaging and face image synthesis ."
27,"photo, editing, generation, framework, gan, image",vided both the discriminator and generator with class information in order to generate samples conditioned on the class . Other recent approaches focused on generating particular images highly relevant to a given text description .
28,"domains, translation, multiple, combustion, image-to-image","Unpaired image-to-image translation frameworks have been proposed . For example, pix2pix learns this task in a supervised manner using cGANs ."
32,"(x), g(x, d, dcls, g","To achieve this, we train G to translate input image x into output image y . We also introduce an auxiliary classifier that allows a single discriminator to control multiple domains ."
37,"target, c, domain, label, classification, loss","For a given input image x and a target domain label c, our goal is to translate x into an output image y, which is properly classified to the target domain c . To achieve this condition, we add an auxiliary classifier on top of D and impose the domain classification loss when optimizing"
40,"losses, g, classification, reconstruction","G is trained to generate images that are realistic and classified to its correct target domain . However, minimizing the losses does not guarantee that translated images preserve the content of its input images while changing only the domain-related part of the inputs ."
45,"stargan, datasets, multiple","StarGAN incorporates multiple datasets containing different types of labels . The label information is only partially known to each dataset . In the case of CelebA and RaFD, the latter contains labels for attributes such as hair color and gender ."
48,cad,"the generator learns to ignore the unspecified labels, which are zero vectors . The structure of the generator is exactly the same as in training with a single dataset . We train the model in a multi-task learning setting ."
55,"discriminator, ar-, cyclegan, network, chitecture","StarGAN has the generator network composed of two convolutional layers with the stride size of two for downsampling, six residual blocks . We use instance normalization but no normalization for the discriminator ."
63,"cgan, model","IcGAN learns the mapping G : z,c  x that generates an image x conditioned on both the latent vector z and the conditional vector c ."
68,"images, celebrities, celebfaces, celebrity, attributes, face, celeba","The CelebFaces Attributes dataset contains 202,599 face images of celebrities . Each annotated with 40 binary attributes . We crop the initial 178 x 218 size images ."
71,"nvidia, software, adam, rafd, gpu, tesla, m40",All models are trained using Adam with B1 = 0.5 and B2 = 0.999 . For data augmentation we flip the images horizontally with a probability of 0.5 . The batch size is set to 16 for all experiments .
73,"multi-step, transfer, cyclegan, multi-attribute, translations",We train the cross-domain models such as DIAT and CycleGAN multiple times . We perform multi-step translations to synthesize multiple attributes .
74,"learning, transfer, framework, multi-task, facial, celeba, attribute",Fig. 4 shows the facial attribute transfer results on CelebA . Our method provides a higher visual quality of translation results on test data . One possible reason is the regularization effect of StarGAN through a multi-task learning framework .
80,"color, age",Each Turker was asked 30 to 40 questions with a few simple yet logical questions for validating human effort . The number of validated Turkers in each user study is 146 and 100 in single and multiple transfer tasks .
85,"amt, tasks, fer, transfer, trans-, multi-attribute",Table 1 and 2 show the results of our AMT experiment on single- and multi-attribute transfer tasks . StarGAN obtained the majority of votes for best transferring attributes in all cases .
86,"translation, transfer, icgan, multi-attribute, image","StarGAN can handle image translation involving multiple attribute changes by randomly generating a target domain label in the training phase . The performance difference becomes significant, e.g., the 'G+A' case in Table 2 ."
89,"identity, personal, expressions, cyclegan, diat, natural-looking",StarGAN clearly generates the most natural-looking expressions . DIAT and CycleGAN mostly preserve the identity of the input . IcGAN even fails to preserve the personal identity in the image .
90,"quality, image","RaFD images contain a relatively small size of samples, e.g., 500 images per domain . When trained on two domains, DIAT and CycleGAN can only use 1,000 images at a time ."
91,"quantitative, evaluation, facial, expression",Quantitative evaluation computes classification error of facial expression on synthesized images . We trained a facial expression classifier on the RaFD dataset using a ResNet-18 architecture .
96,"discriminator, cross-domain, source-target, cyclegan, mod-, pair, domain, els","The last column in Table 3 shows that the number of parameters required to learn all translations by StarGAN is seven times smaller than that of DIAT . This is because StarGan requires only a single generator and discriminator pair . In case of cross-domain models such as CycleGAN, a completely different model"
98,"celeba, dataset, ra, rafd","Wir train our model jointly on the CelebA and RaFD datasets . To distinguish between the model trained only on RaFD and the model training on both Celeb A and RFD, we denote the latter as StarGAN-SNG ."
99,"qualitative, tasks, rafd, celeba, low-level, comparisons",StarGAN-JNT exhibits emotional expressions with high visual quality . StargAN-SNG generates reasonable but blurry images with gray backgrounds . This difference is due to the fact that Star GAN-YNT learns to translate CelebA images during training .
103,"mask, vector, data, validation, set","StarGAN-JNT fails to synthesize facial expressions, and it manipulates the age of the input image . This is because the model ignores the facial expression label as unknown and treats the facial attribute label as valid by the mask vector ."
105,"learning, translation, multi-task, setting, image","In this paper, we proposed StarGAN, a scalable imageto-image translation model among multiple domains using a single generator and a discriminator . Besides the advantages in scalability, starGAN generated images of higher visual quality compared to existing methods . In addition, the proposed simple mask"
106,"of, national, foundation, clova, korea, research, ai","This work was mainly done while the first author did a research internship at Clova AI Research, NAVER . We thank all the researchers at NAVER, especially Donghyun Kwak, for insightful discussions ."
109,"wand, w, m., cvpr, arjovsky","In Proceedings of the 34th International Conference on Machine Learning , pages 214-223, 2017. 5 A. Brock, T. Lim, J. M. Ritchie, and N. Weston. Neural photo editing with introspective adversarial networks. In Advance in Neural Information Processing Systems ."
110,"auxiliary, translation, synthesis, generative, classifier, image-to-image, network, gans, adversarial, image","A. Odena, C. Olah, and J. Shlens. Conditional image synthesis with auxiliary classifier gans . arXiv preprint arxiv:1610.09585, 2016. 3, 5 G. Perarnau, J. van de Weijer, B."
114,"celeba, label, rafd, ra",StarGAN is a two-dimensional one-hot vector which indicates whether the CelebA or RaFD label is valid . The label for RaFD provides information on categorical attributes .
119,"leaky, relu, network, architecture","The network architectures of StarGAN are shown in Table 4 and 5 . For the generator network, we use instance normalization in all layers except the last output layer . There are some notations ."
