element_idx,keywords,summarized_text
4,"window, sliding, network, classification, localization, convolutional","We present an integrated framework for using Convolutional Networks for classification, localization and detection . We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet ."
6,"imagenet, image, networks, convolutional, index","Convolutional Networks have been applied for many years . The accuracy of ConvNets on small datasets such as Caltech-101 has not been record-breaking . However, the advent of larger datasets has enabled Convnets to significantly advance the state of the art on datasets like the 1000-catego"
8,"accuracy, predictions, convnet, training, localization","The main point of this paper is to show that training a convolutional network to simultaneously classify, locate and detect objects in images can boost the classification accuracy . The paper proposes a new integrated approach to object detection, recognition, and localization with a single ConvNet ."
12,"window, fashion, convnet, fun, function, image","The first idea in addressing this is to apply a ConvNet at multiple locations in the image, in a sliding window fashion, and over multiple scales . Even with this, many viewing windows may contain a perfectly identifiable portion of the object . This leads to decent classification but poor localization and detection ."
14,"parameters, body, pose, window, convnet, viewing, instantiation","Osadchy et al. describe a ConvNet for simultaneous face detection and pose estimation . Faces are represented by a 3D manifold in the nine-dimensional output space . When the training image is a face, the output is pushed away from the known pose ."
15,"object, computer, window, vision, convnet, localization, viewing","ConvNet-based segmentation can classify the central pixel of its viewing window as a boundary between regions or not . But when the regions must be categorized, it is preferable to perform semantic segmentation . The disadvantage is that it requires dense pixel-level labels for training ."
16,"performance, convnet, classification, localization",Krizhevsky et al. recently demonstrated impressive classification performance using a large ConvNet . The authors also entered the ImageNet 2012 competition .
24,"imagenet, chal-, lenge, scale, number, recognition, large, visual, image","Throughout the paper, we report results on the 2013 ImageNet Large Scale Visual Recognition Challenge . Each image is assigned a single label corresponding to the main object in the image . Five guesses are allowed to find the correct answer . To be considered correct, the predicted box must match the groundtruth by at"
26,"detection, task, localization, method","The localization task is a convenient intermediate step between classification and detection . In Fig. 1, we show examples of images with our localization/detection predictions and corresponding groundtruth . Note that classification and localization share the same dataset ."
32,"imagenet, 2012, classification, training, set, image",We train the network on the ImageNet 2012 training set . Each image is downsampled so that the smallest dimension is 256 pixels . We then extract 5 random crops of size 221x221 pixels and present them to the network in mini-batches of size 128 . The weights in the network
33,"architecture, space, road","Layers 1-5 are similar to Krizhevsky et al., using rectification non-linearities and max pooling . We treat this architecture as non-spatial, as opposed to the inference step, which produces spatial outputs ."
36,"spatial, model, size, accurate, fast","Layer 5 is the top convolutional layer . Subsequent layers are fully connected, and applied in sliding window fashion . Similar sizes for accurate model can be found in the Appendix ."
39,"power-ful, feature, computer, extractor, vision, features","We release a feature extractor named ""OverFeat"" 1 in order to provide powerful features for computer vision research . Two models are provided, a fast and accurate one . Each architecture is described in tables 1 and 3 ."
42,"of, window, size, convnet, sliding, arbitrary, image",We explore the entire image by densely running the network at each location and at multiple scales . This approach yields significantly more views for voting . The result of convolving a ConvNet on an image of arbitrary size is a spatial map of C-dimensional vectors at each scale .
43,"ratio, subsampling, window, total, network, windows","The better aligned the network window and the object, the strongest the confidence of the network response . To circumvent this problem, we apply the last subsampling operation at every offset . This removes the loss of resolution from this layer ."
48,"output, feature, pooled, c-dimensional, fashion, vector, maps, sliding-window",Each of unpooled maps undergoes a 3x3 max pooling operation . The classifier has a fixed input size of 5x5 and produces a C-dimensional output vector .
50,"classification, y",20 pixel unpooled layer 5 feature map . max pooling over non-overlapping 3 pixel groups . 5 pixel classifier is applied in sliding window fashion .
53,"map, 5, feature, layer, extraction, 5x5, input, fixed-size","In the feature extraction portion, the filters are convolved across the entire image in one pass . This is far more efficient than sliding a fixed-size feature extractor over the image . However, these principles are reversed for the classifier portion of the network ."
55,"model, multi-scale, approach, gains","In Table 2, we experiment with different approaches, and compare them to the single network model of Krizhevsky et al. For reference . The approach described above achieves a top-5 error rate of 13.6% ."
62,"dataset, ilsvrc13",Our model obtained 14.2% accuracy by voting of 7 ConvNets . The best accuracy using only ILSVRC13 data was 11.7% . Pre-training with extra data from the ImageNet Fall11 dataset improved this number to 11.2% .
64,"sliding-window, convolution, approach, convnets",ConvNets are inherently efficient when applied in a sliding fashion . We apply each convolution over the extent of the full image . This extends the output of each layer to cover the new image size .
73,"bounding, layer, final, regression, box, network, classification","To generate object bounding box predictions, we simultaneously run the classifier and regressor networks across all locations and scales . Since these share the same feature extraction layers, only the final regression layers need to be recomputed after computing the classification network . The output of the final softmax layer for a class"
82,"bounding, regression, box, classification, network","We train the regression network using an l2 loss between the predicted and true bounding box . The final regressor layer is class-specific, having 1000 different versions . We train this network using the same set of scales as described in Section 3 ."
83,"multi-scale, manner, across-scale, prediction","Training on a single scale will perform well on that scale and still perform reasonably on other scales . However training multi-scale will make predictions match correctly across scales and exponentially increase the confidence of the merged predictions . In turn, this allows us to perform well with a few scales only, rather than many scale"
93,"bounding, confidence, matching, maximum, scores, final, box, classification, prediction",The final prediction is given by taking the merged bounding boxes with maximum class scores . This is computed by cumulatively adding the detection class outputs associated with the input windows from which each bounding box was predicted .
100,"pcr, class, layer, top, each",using a different top layer for each class in the regressor network did not outperform using only a single network shared among all classes . This may be because there are relatively few examples per class annotated with bounding boxes in the training set .
102,"detection, examples, training, negative",Detection training is similar to classification training but in a spatial manner . Multiple location of an image may be trained simultaneously . The main difference with the localization task is the necessity to predict a background class when no object is present .
109,"detection, accuracy, drops, bas, segmentation, based, method","method yields 11.5% mAP). This technique speeds up inference and substantially reduces the number of potential false positives . Combined with our method, we may observe similar improvements ."
111,"uva, nec, validation, distribution, set",NEC and UvA did not fine tune on the detection validation set . The validation and test set distributions differ significantly enough that this alone improves results by approximately 1 point .
113,"detection, approach, window, sliding, convnet","We have presented a multi-scale, sliding window approach that can be used for classification, 1ocalization and detection . We applied it to the ILSVRC 2013 datasets and it currently ranks 4th in classification . A second important contribution of our paper is explaining how ConvNets can be effectively used for detection"
114,"bounding, box, training, network, localization","for localization, we are not currently back-propping through the whole network . Swapping the loss to this should be possible since IOU is still differentiable . Alternate parameterization of the bounding box may help to decorrelate the outputs ."
116,"c, cvpr","J. Carreira, F. Li, and C. Sminchisescu. Constrained parametric min-cuts for automatic object segmentation, release 1. http://sminctikexcu.ins.uni-bon.de/code/cpmo/ D. C. Ciresan, J"
118,"digit, handwritten","In NIPS, 2012. Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and P. Haffner. Gradient-based learning applied to document recognition . In Proceedings of the IEEE, 86:22"
126,"multiscale, dimensions, spatial, approach","Table 5: Spatial dimensions of our multi-scale approach . 6 different sizes of input images are used, resulting in layer 5 unpooled feature maps of differing spatial resolution ."
