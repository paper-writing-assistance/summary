element_idx,keywords,summarized_text
4,"financial, reports, statements","In this work, we focus on answering deep questions over financial data . In contrast to existing tasks on general domain, the finance domain includes complex numerical reasoning and understanding of heterogeneous representations . To facilitate analytical progress, we propose a new large-scale dataset, FINQA, with Question-Answering"
6,"analysis, ratio, quality, financial",Financial analysis is a critical means of assessing business performance . Such analysis demands advanced expertise in reasoning among heterogeneous data sources and performing complex numerical reasoning . These challenges are compounded by poor analysis .
9,"capabilities, drop, questions, answering, dataset","NLP studies explored numerical reasoning capabilities needed to answer questions correctly . For example, the DROP dataset focused on Wikipedia-based questions that require numerical reasoning . Financial QA is more challenging than classic QA because it requires the system to spot relevant information across heterogeneous sources . It also takes substantial knowledge to ask meaningful"
10,"net, financial, qa, positions, tax, finqa, change","FINQA contains 8,281 financial QA pairs based on earnings reports of S&P 500 companies . Eleven finance professionals collectively constructed the dataset . The reason-based questions require information from both tables and unstructured texts ."
21,"qa, retriever-generator, framework","Equipped with pretrained language models such as BERT and RoBERTa, our proposed approach outperforms all other baselines and achieves an execution accuracy of 65.05%."
27,"drop, math, mathqa",There have been several QA datasets involving numerical understandings and calculations . The major source is from structured tables or knowledge bases . Popular datasets include Complex WebQuestions .
29,"financial, reports",Recent works attempt to develop pre-trained models specialized for finance domain . There is no previous work and dataset on building QA systems of numerical reasoning on financial reports.
32,"timing, tables, financial, information","Gi is all the correct programs to evaluate to the answer . For financial tables, there is typically a description header . Each row has its name on the left ."
34,"operations, algebra, accounting, table, aggregation, linear, tions, mathematical, opera-","We include 10 common types of operations in our dataset . There are 6 mathematical operations: add, subtract, multiply, divide, greater, exp, and 4 table aggregation operations . The mathematical operations take arguments of either numbers from the given reports or a numerical result from a previous step ."
36,"appendix, a, table, row, names","Table operations take arguments of table row names . We use the special token #n to denote the result from the nth step . For example, in Figure 1, the program consists of 3 steps ."
37,"mathqa, math","Previous studies on QA with numerical reasoning only evaluate the execution accuracy, i.e., the final results from the generated programs, such as DROP and MathQA . However, the applications for the finance domain generally pose much higher requirements of explainability and transparency . Therefore, we also provide the gold programs for our dataset"
43,"tedious, structures, contents, nested, tables, complex, fintabnet, with","a total of 12,719 pages were selected for further annotation . For the tables with 2 description headers, we merge them into a single header ."
45,"expert, experts, recruiting, annotator","We postjob ads on UpWork3 and hire eleven US-based experts with professional finance backgrounds . Each hire is interviewed using four example report pages . After hiring, each annotator first goes through a training session ."
47,"mechanical, qa, turk, amazon, dataset","We do not use popular micro-task platforms, such as Amazon Mechanical Turk . Our experiment with MTurk workers in S 4.3 echo this observation ."
48,"question, financial, reports, meaningful",The annotators are asked to write a meaningful financial question . Each page is assigned to one or two experts for annotation . We detail each part as follows .
50,"questions, validation","the annotators are then asked to elaborate the operation steps to answer the question . The ""operation"" is one of the ten predefined operations described in 3 . For operations that only use one argument, such as table aggregation, workers can leave argument2 blank ."
52,"inter-annotator, experts, agreement, external, finqa","External experts answer FINQA questions with a high accuracy and inter-annotator agreement . The payment is $2.0 per question . For program accuracy, they reach 89.44% and 85.53% ."
53,"non-expert, questions, crowd, finqa, workers",Non-expert crowd workers answer FINQA questions with a low accuracy . We distribute samples to MTurk4 and take the similar process to distribute each example to two workers .
59,"information, table, answer, to, finqa","Statistics of Supporting Facts. In FINQA, 23.42% of the questions only require the information in the text to answer . 46.30% of the examples have one sentence or one table row as the fact . 11.07% has more than two pieces of facts."
60,"divide, add, reasoning, programs, finqa","Statistics of Reasoning Programs is common in financial analysis . In FINQA, 59.10% of the programs have 1 step, 32.71% have 2 steps, and the rest 8.19% have 3 or more steps ."
68,"report, bert, window, sliding, input","For the tables, we use templates to turn each row into sentences . For example, the last row of the table in Figure 1 is represented as 'the risk-free interest , We concatenate each suprate of 2006 is 5%;   porting fact with the question and train a class"
69,"dsl, tokens, retriever, question","Program Generator Given the retrieved supporting facts from the retriever, the program generator aims to generate the executable program to answer the question . The generated tokens come from 3 sources: 1) The input passage and the question tokens ei, like the numbers or the table row names . 2) The special tokens"
84,"symbolic, mathqa, reader, neural, dataset","The Neural Symbolic Reader is a pointergenerator based model for program generation . Different from ours, it directly learns the program with nested format as a sequence . This way the model is able to learn the program structures as patterns from very large-scale data ."
88,"optimizer, finbert, bert-base, adam","Experiment Setups. For the retriever, we use BERT-base as the classifier . For all models, we experiment on using BERT , RoBERTa , and FinBert ."
90,"finbert, retriever-generator, pipeline, model, domain, based, finance","For the BERT-based retriever, we have 89.66% recall for the top 3 retrieved facts . We use the same retriever results for all retriever-generator based models . Directly generating the execution results gives nearzero scores ."
93,"finbert, bert-large, bert, bert-lar","The performance of using FinBert is no better than BERT-large, mostly because its pre-training corpus is limited . We run the program generator using the gold retriever result ."
105,"constants, yield, numbers, implicit, constant","constant ""1,000"" converts ""1.5 billion"" to ""1,500 million"" A constant is also used to explicate the implicit numbers hidden in the language . For example, to calculate ""the average for the year 2012, 2013, and 2014"", the program needs to use the constant ""3"" as the denominator ."
107,"financial, knowledge, numerical, model, finqanet, reasoning","We sample 50 error cases from the results of the FinQANet model and analyze them manually . 15% of the errors are caused by the retriever, e.g., missing facts . And the rest half are primarily numerical reasoning errors, including complex programs with multiple steps ."
110,"abilities, pre-training, finqa",We propose baseline frameworks and conduct comprehensive experiments and analysis . The results show that current large pre-trained models still fall far behind the human expert performance . This encourages potential future work on developing pre-training tasks .
112,"license, 500, fintabnet, s&p, companies, data, access, dataset",FinTabNet dataset is publicly available under CDLA-PermissiveÂ° license . We create additional annotations on top of the data .
113,"compensation, job, large-scale, speed, work, dataset, finqa","We first launch interviews of the task introduction with 4 example questions, which is paid as $30, for them to try a few examples to get informed and familiar with the task . Then based on their consent to continue working on the large-scale job, we discuss with the workers to reach agreements on the compensation before starting the large"
120,emnlp,"A multilayer perceptron based ensemble technique for fine-grained financial sentiment analysis . Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Copenhagen, Denmark, September 911, 2017, pages 540-546. Association for Computational Linguistics."
122,"problem, math, aida, word, amini",Mathqa: Towards interpretable math word problem solving with operation-based formalism . In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies .
125,"icml, 2020, solutions, natural-language, problems","Kezhen Chen, Qiuyuan Huang, Hamid Palangi, Paul Smolensky, Kenneth D. Forbus, and Jianfeng Gao. 2020a. Mapping natural-language problems to formal-language solutions using structured neural representations."
131,"language, human, technologies, bert","BERT: pre-training of deep bidirectional transformers for language understanding . Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019."
132,"ing, discrete, comprehension, benchmark, requir-","Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. 2019. DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs."
144,"liang, semi-structured, tables, association, computational, percy, for, linguistics","Association for Computational Linguistics and 7th International Joint Conference on Natural Language Processing, ACL 2015, July 26-31, 2015, Beijing, China, Volume 1: Long Papers ."
148,"emnlp, emnlp-ijcn, emnlp-ijcnlp","Weikang Wang, Jiajun Zhang, Qian Li, Chengqing Zong, and Zhifei Li. detecting identity fraud via dialogue interactions ."
150,"answer-, ing","Hotpotqa: A dataset for diverse, explainable multi-hop question answering . In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018, pages 2369-2380."
151,"long-scale, complex, scale, large, dataset","Spider: A largescale human-labeled dataset for complex semantic parsing and text-to-sql task. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium ."
156,"titan, tf-idf, rtx, gpu",All the implementation and pre-trained models are conducted on TITAN RTX GPUs . We use the Adam optimizer from the Scikit-learn library . FinQANet The learning rate is set as 1e-5 .
168,"tax, part, treatment, d, activity, medicare","the ppaca effectively changes the tax treatment of federal subsidies paid to retiree health benefit sponsors that provide a benefit that is at least actuarially equivalent to the benefits under medicare part d . the acts effectively make the subsidy payments taxable in tax years beginning after december 31 , 2012 ."
174,"net, understanding, table, row, change","Figure 5: Error case study 1: The net change in the tax position is the sum of the increase and the decrease plus the penalties and interest . The model lacks this finance knowledge, thus the retriever fails to retrieve the correct table rows and sentences ."
176,"profit, underlying, sga, operating, measures, gross",underlying gross margin declined by 180 basis points in 2012 as a result of cost inflation . underlying sga% was consistent with 2011 .
180,"profit, underlying, margin, operating, gross","underlying gross margin declined by 110 basis points in 2013 due to the impact of inflation , net of productivity savings , lower operating leverage due to lower sales volume . The underlying operating profit of 2013 is $ 2098 . In 2013 we recorded $ 42 million of charges associated with cost reduction initiatives ."
