element_idx,summarized_text,keywords
5,"In the Transformer model, ""self-attention"" combines information from attended embeddings . This makes attention weights unreliable as explanations probe . In this paper, we consider the problem of quantifying this flow of information .","token, input, rollout, tokens, self-attention, attention"
9,"Attention has become the key building block of neural sequence processing models, and visualizing attention weights is the easiest and most popular approach to interpret a model's decisions . Although it is wrong to equate attention with explanation , it can offer plausible and meaningful interpretations .","sequence, neural, attention, models, processing"
10,"We propose two simple but effective methods to compute attention scores to input tokens at each layer . These methods are based on modelling the information flow in the network with a DAG . The first method, attention rollout, assumes that the identities of output tokens are linearly combined through the layers . To adjust attention","hidden, raw, attention, embedding, graph"
23,"In our analysis, we focus on the verb number prediction task . We use the subjectverb agreement dataset . This task and dataset offer a clear hypothesis about what part of the input is essential to get the right solution .","task, agreement, pre-diction, singularity, dataset"
24,"The model has 6 layers, and 8 heads, with hidden/embedding size of 128 . Similar to Bert we add a CLS token and embedding in the final layer . The accuracy of the model on the subject-verb agreement task is 0.96 .","encoder, gpt-, 2, transformer, blocks"
27,"ure 2 gives raw attention scores of the CLS token over input tokens at different layers . These observations reflect the fact that as we go deeper into the model, the embeddings are more contextualized .","token, input, scores, raw, attention, cls"
28,"Blank-out replaces each token in the input, one by one, with UNK . We compute the Spearman's rank correlation COefficient . The correlation between raw attention weights of the CLS token and blank-out scores is rather low .","class, input, raw, gradients, correct, attention, weights"
36,"In a Transformer block, both self-attention and feed-forward networks are wrapped by residual connections, i.e., the input to these modules is added to their output . When we only use attention weights to approximate the flow of information in Transformers, we ignore the residual connections . To compute attention rollout and","rollout, attention, weights, residual, connections, graph"
37,"analyzing individual heads requires accounting for mixing information between heads through a position-wise feed-forward network in Transformer block . Using attention rollout and attention flow, it is also possible to analyze each head separately .","flow, network, out, attention, head, roll-"
39,"In the attention graph, a path from node v at position k in li is a series of edges that connect these two nodes . To compute the total amount of information propagated from v to u, we multiply the weights of all edges in that path .","nodes, transferred, attention, between, two, graph, information"
41,"In graph theory, a flow network is a directed graph with a ""capacity"" associated with each edge . For each edge the flow value should not exceed its capacity, |fuv  cuv| .","network, attention, value, flow"
42,"We can compute the maximum attention flow from any node in any of the layers to any input nodes . In attention flow, the weight of a single path is the minimum value of the weights of the edges .","maximum, flow, network, attention, value"
48,"Figure 1 depicts raw attention, attention rollout and attention flow for a correctly classified example across different layers . It is noteworthy that the first layer of attention rolls out is the same, and their only difference with raw attention is the addition of residual connections .","flow, rollout, attention, residual, connections"
49,"Figures 2 and 3 show the weights from raw attention, attention rollout and attention flow . The second example is ""the article on NNP large systems ?>"" The model correctly classifies this example and changing the subject of the missing verb from ""article"" to ""articles"" flips the decision of the model","flow, raw, rollout, attention, cls"
54,"In the miss-classified example, both attention rollout and attention flow assign relatively high scores to both the subject of the verb and the attractor, ""systems"" this can explain the wrong prediction of the model .","flow, high, relatively, rollout, attention, weights, assign"
55,Attention flow can indicate a set of input tokens that are important for the final decision . Attention rollout weights are more focused compared to attention flow weights .,"flow, weights, rollout, attention"
59,"Attention flow views them as capacities, and at every step of the algorithm, it uses as much of the capacity as possible . Attention rollout computes the maximum possibility of token identities to propagate to the higher layers . This makes attention rollout stricter than attention flow .","token, rollout, identities, weights, attention"
61,"Table 3 shows the correlation of the importance score obtained from raw attention, attention rollout and attention flow from a DistillBERT model fine-tuned to solve ""SST-2""","glue, attention, rollout, benchmark"
62,"In Figure 4, we show an example of applying these methods to a pre-trained Bert to see how it resolves the pronouns in a sentence . Next, we look at the prediction of the model for the masked word and compare the probabilities assigned to ""her"" and ""his"" Then we","flow, raw, rollout, bert, attention, weights"
65,"In this paper, we insisted on sticking with simple ideas that only require attention weights and can be easily employed in any task or architecture that uses self-attention . We should note that all our analysis in this paper is for a Transformer encoder .","attention, transformer, flow, decoder"
99,"We could either analyze attention heads separately, or we could average all heads and have a single attention graph . It is possible to analyse the role of each head in isolation of all other heads . We will treat all the layers below the layer of interest as single head layers .","graph, setup, attention, multi-head"
