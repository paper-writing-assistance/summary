element_idx,keywords,summarized_text
5,"vision, recognition, network, setting, convolutional, image",In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting . Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small convolution filters . This shows that a significant improvement on the prior-art configurations can be achieved by
7,"imagenet, networks, recognition, large-scale, visual, convolutional, image","Convolutional networks have enjoyed a great success in large-scale image and video recognition which has become possible due to large public image repositories . ImageNet Large-Scale Visual Recognition Challenge has served as a testbed for a few generations . In particular, an important role in the advance of deep visual"
8,"layer, design, depth, network, convolutional","a number of attempts have been made to improve the original architecture of Krizhevsky et al. in a bid to achieve better accuracy . For example, the best-performing submissions to the ILSVRC2013 utilised smaller receptive window size and smaller stride of the first convolution"
9,"convnet, datasets, recognition, image","ConvNet architectures achieve the state-of-the-art accuracy on ILSVRC classification and localisation tasks . They are also applicable to other image recognition datasets, where they achieve excellent performance even when used as part of a relatively simple pipelines ."
17,"configuration, layer, convnet","In this section, we first describe a generic layout of our ConvNet configurations and then detail the specific configurations used in the evaluation ."
19,"convolution, layer, stride, input, convolutional",the input to our ConvNets is a fixed-size 224 x 224 RGB image . The only preprocessing we do is subtracting the mean RGB value from each pixel . In one of the configurations we also utilise 1 x 1 convolution filters .
21,"normalisation, non-linearity, local, (lrn), rectification, response","Local Response Normalisation normalisation does not improve performance on the ILSVRC dataset, but leads to increased memory consumption and computation time . Where applicable, the parameters for the LRN layer are those of ."
23,"layer, conv., network","ConvNet configurations are evaluated in Table 1 . The width of conv. layers is rather small, starting from 64 in the first layer and then increasing by a factor of 2 after each max-pooling layer ."
26,"fields, layer, ilsvrc-2013, field, receptive, conv.","ConvNet configurations are quite different from the ones used in the top-performing entries of the ILSVRC-2012 and ILVSRC-2013 competitions . We use very small 3 x 3 receptive fields throughout the whole net, which are convolved with the input at every pixel "
33,"x, convolution, layer, 3, rectification, nonlinear, stack","a stack of three 3 x 3 conv. layers instead of a single 7 x 7 layer can be seen as imposing a regularisation on the filters, forcing them to have a decomposition through the filters . assuming that both the input and output of the three-layer stack has C channels,"
34,"configuration, c","1 x 1 conv. layers have recently been utilised in the ""Network in Network"" architecture of Lin et al."
35,"deep, convolution, number, recognition, street, ilsvrc, filters","Small-size convolution filters have been previously used by Ciresan et al. but their nets are significantly less deep than ours, and they did not evaluate on the large-scale ILSVRC dataset . GoogLeNet was developed independently of our work, but is similar in that it is "
38,"accuracy, topology, network, classification, single-network","our model is outperforming that of Szegedy et al. in terms of the single-network classification accuracy . The network topology is, however, more complex than ours ."
42,"images, multi-scale, convnet, training","ConvNet training was regularised by weight decay and dropout regularisation for the first two fully-connected layers . The learning rate was initially set to 10-2 and then decreased by a factor of 10 when the validation , set accuracy stopped improving ."
43,"deep, nets, initialisation, network, weights","The initialisation of the network weights is important, since bad initialisation can stall learning due to the instability of gradient in deep nets . After training deeper architectures, we initialised the first four convolutional layers and the last three fully connected layers with the layers of net A ."
45,"input, convnet, training, image","S is the smallest side of an isotropically-rescaled training image, from which the ConvNet input is cropped . For S = 224 the crop will capture whole-image statistics ."
46,"=, convnet, 384, network, s","In our experiments, we evaluated models trained at two fixed scales: S = 256 . To speed-up training of the S = 384 network, it was initialised with weights pre-trained ."
52,"net, smallest, fully-convolutional, side, input, convolutional, image","First, it is isotropically rescaled to a pre-defined smallest image side, denoted as Q . We note that Q is not necessarily equal to the training scale S . The resulting fully-convolutional net is then applied to the whole image ."
53,"feature, convolution, convolved, evaluation, multi-crop, maps",Multi-crop evaluation is complementary to dense evaluation due to different convolution boundary conditions . In the case of dense evaluation the padding for the same crop naturally comes from the neighbouring parts of an image .
55,"multi-gpu, c++, toolbox, training, caffe","Multi-GPU training exploits data parallelism, and is carried out by splitting each batch of training images into several GPU batches . Gradient computation is synchronous across the GPUs, SO the result is exactly the same as when training on a single GPU ."
56,"net, convnet, training, speed, up","ConvNet training has been recently proposed . On an off-the-shelf 4-GPU system, training a single net took 2-3 weeks depending on the architecture ."
58,"convnet, classification, architecture, validation, dataset, image",the ILSVRC-2012 dataset includes images of 1000 classes . The classification performance is evaluated using two measures: the top-1 and top-5 error .
66,"shallow, net, larger, convnet, filters, conv.","configuration C performs worse than configuration D, which uses 3 x 3 conv. layers throughout the network . The error rate of our architecture saturates when the depth reaches 19 layers, but even deeper models might be beneficial for larger datasets . We also compared the net B with a shallow net with five"
71,"testing, convnet, scale, model","Scale jittering at test time consists of running a model over several rescaled versions of a test image . The models trained with fixed S E were evaluated over three test image sizes . At the same time, scale jitters at training time allows the network to be applied to a wider range"
74,"4, table, scale, jittering",scale jittering at test time leads to better performance . Our best single-network performance on the validation set is 24.8%/7.5% top-1/top-5 error .
78,"crops, convolution, evaluation, convnet, multiple, boundary, conditions",In Table 5 we compare dense ConvNet evaluation with mult-crop evaluation . We also assess the complementarity of the two methods by averaging softmax outputs .
83,"e, ilsvrc, multi-scale, model","The resulting ensemble of 7 networks has 7.3% ILSVRC test error . After the submission, we considered an ensemble of only two best-performing multi-scale models . This reduced the test error to 7.0% using dense evaluation ."
91,"winning, ilsvrc-2013, submission, convnet, architecture, performance, single-net, clarifai",ConvNets significantly outperform previous generation of models . Our result is competitive with respect to the classification task winner . Clarifai achieved 11.2% with outside training data and 11.7% without it .
95,"deep, representations, convnet, visual, architecture, image","In this work we evaluated very deep convolutional networks for largescale image classification . It was demonstrated that the representation depth is beneficial for the classification accuracy . In the appendix, we also show that our models generalise well to a wide range of tasks and datasets ."
132,"convolutional, recognition, networks, visual","CoRR, abs/1409.0575, 2014. Simonyan, K., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., and LeCun, Y. OverFeat: Integrated Recognition, Localization andDetection using Con"
134,"task, localisation, ilsvrc-2013","In the main body of the paper we have considered the classification task of the ILSVRC challenge, and performed a thorough evaluation of ConvNet architectures of different depth . In this section, we turn to the localisation task, which we have won in 2014 with 25.3% error . It can be seen as "
136,"bounding, convnet, width, box, localisation","A bounding box is represented by a 4-D vector storing its center coordinates, width, and height . In the latter, the last layer is 4-D, while in the latter it is 4000-D . We use the ConvNet architecture D , which contains 16 weight layers ."
137,"corresponding, convnet, training, classification, localisation, models","Training of localisation ConvNets is similar to that of the classification . The main difference is that we replace the logistic regression objective with a Euclidean loss, which penalises the deviation of predicted bounding box parameters from the ground-truth ."
139,"merging, convnet, whole, classification, procedure, localisation, image","the second, fully-fledged, testing procedure is based on the dense application of the localisation ConvNet to the whole image . To come up with the final prediction, we utilise the greedy merging procedure of Sermanet et al."
144,"criterion, setting, ilsvrc, localisation, error",In this section we first determine the best-performing localisation setting . The localisation error is measured according to the ILSVRC criterion .
145,"(pcr), class-agnostic, comparison, single-class, per-class, regression, settings, fine-tuning, (scr)","Per-class regression outperforms the class-agnostic single class regression . In these experiments, the smallest images side was set to S = 384; the results with S = 256 exhibit the same behaviour ."
148,"crop, computer, localisation","Having determined the best localisation setting, we now apply it in the fully-fledged scenario . the top-5 class labels are predicted using our best-performing classification system ."
151,"performance, ilsvrc-2014, advancement, localisation",We compare our best localisation result with the state of the art in Table 10 . Our results are considerably better than those of the ILSVRC-2013 winner Overfeat . We envisage that better localisation performance can be achieved .
158,"model, methods, large, state-of-the-art, ilsvrc","deep image representations, learnt on ILSVRC, generalise well to other datasets . In this evaluation, we consider two models with the best classification performance . if our models lead to better performance than more shallow models used in state-of-the-art methods ."
159,"descriptor, convnet, classification, ilsvrc, image","To utilise ConvNets, pre-trained on ILSVRC, we remove the last fully-connected layer . The resulting image descriptor is L2-normalised and combined with a linear SVM classifier, trained on the target dataset ."
160,"image, ilsvrc, statistics, descriptor","Aggregation of features is carried out in a similar manner to our ILSVRC evaluation procedure . Namely, an image is first rescaled SO that its smallest side equals Q, and then the network is densely applied over the image plane . We then perform global average pooling on the resulting"
163,"task, voc-2007, classification, image",Image Classification on VOC-2007 and VOC2012 . These datasets contain 10K and 22.5K images respectively . Each image is annotated with one or several labels .
167,"aggregation, descriptors, image","We hypothesize that this is due to the fact that in the VOC dataset the objects appear over a variety of scales, SO there is no particular scale-specific semantics which a classifier could exploit . averaging has a benefit of not inflating the descriptor dimensionality ."
168,"pipeline, representations, identification, ilsvrc, dataset, image",Wei et al. achieves 1% better mAP on VOC-2012 . It also benefits from the fusion with an object detection-assisted classification pipeline .
169,"caltech-101, test, classification, image",Caltech-101 contains 9K images labelled into 102 classes . Caltech 256 is larger with 31K images and 257 classes. A standard evaluation protocol on these datasets is to generate several random splits into training and test data .
170,"caltech, voc, multi-scale, image",On Caltech datasets the stacking of descriptors performs better than averaging or max-pooling . This can be explained by the fact that in Caltech images objects typically occupy the whole image .
171,"caltech-256, 11, caltech-101, table","On Caltech-256, our features outperform the state of the art by a large margin . The deeper 19-layer Net-E performs better than the 16-layer net-D ."
172,"map, action, classification, training, settings","PASCAL VOC-2012 action classification task consists in predicting an action class from a single image, given a bounding box of the person performing the action . The dataset contains 4.6K training images, labelled into 11 classes ."
174,"al., tasks, girshick, et, recognition, image","Since the public release of our models, they have been actively used by the research community for a wide range of image recognition tasks . For example, Girshick et al. achieve the state of the object detection results by replacing the ConvNet of Krizhevsky with our 16-layer model . Similar gains"
