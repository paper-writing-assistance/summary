element_idx,keywords,summarized_text
4,"bottom-up, cnn, proposals, region","The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context . In this paper, we propose a simple and scalable detection algorithm that improves mean average precision by more than 30% relative to the previous best result on VOC 2012-achieving a mAP of 53."
6,"detection, object, voc, pascal, recognition, visual, task","the last decade of progress on various visual recognition tasks has been based considerably on the use of SIFT and HOG . but if we look at performance on the canonical visual recognition task, PASCAL VOC object detection, it is generally acknowledged that progress has been slow during 2010-2012 ."
10,"detection, r-cnn, bottom-up, region, proposals, average, precision, mean, road",Figure 1: Object detection system overview . R-CNN achieves a mean average precision of 53.7% on PASCAL VOC 2010 . The popular deformable part models perform at 33.4% .
12,"fukushima, shift-invariant, neocognitron, model","Fukushima's ""neocognitron"" was a biologically-inspired hierarchical model for pattern recognition . LeCun et al. showed that stochastic gradient descent via backpropagation was effective ."
13,"cnn, vector, recognition, support, classification, machines, image","In 2012, Krizhevsky et al. rekindled interest in CNNs . Their success resulted from training a large CNN on 1.2 million labeled images ."
18,"detection, object, cnn, classification, image","This paper is the first to show that a CNN can lead to dramatically higher object detection performance on PASCAL VOC . To achieve this result, we focused on two problems: localizing objects with a deep network and training a high-capacity model with only a small quantity of annotated detection data."
19,"cnn, classification, sliding-window, detector, image","CNNs have been used in this way for at least two decades . In order to maintain high spatial resolution, these CNNs typically only have two convolutional and pooling layers ."
20,"computation, region, regions, proposals, cnn, with","We use a simple technique to compute a fixed-size CNN input from each region proposal . At test time, our method generates around 2000 category-independent region proposals . We then classifies each region with category-specific linear SVMs ."
21,"detection, r-cnn, head-to-head, comparison, overfeat, ilsvrc2013","In this updated version of this paper, we provide a headto-head comparison of R-CNN and the recently proposed OverFeat detection system . We show that a sliding-window CNN significantly outperforms Overfeat with a mAP of 31.4% versus 24.3%."
23,"auxiliary, cnn, high-capacity, large, fine-tuning, dataset","supervised pre-training, followed by domainspecific fine-tuning on a small dataset is an effective paradigm for learning high-capacity CNNs when data is scarce . We point readers to contemporaneous work by Donahue et al., who show that Krizhevsky's CNN"
28,"2010-12, cascal, voc",Our object detection system consists of three modules . The first generates category-independent region proposals . These proposals define the set of candidate detections available to our detector .
34,"cpmc, proposals, objectness, region",R-CNN is agnostic to the particular region proposal method . We use selective search to enable a controlled comparison with prior detection work .
36,"cnn, warped, data, training, image","In order to compute features for a region proposal, we must first convert the image data in that region into a form that is compatible with the CNN . Prior to warping, we dilate the tight bounding box SO that at the warped size there are exactly p pixels of warped image context around the original box "
38,"compute, search, selective, svm, cnn, features","At test time, we run selective search on the test image to extract around 2000 region proposals . For each class, we score each extracted feature vector using the SVM trained for that class . Given all scored regions in an image, we apply a greedy non-maximum suppression that rejects a region if it"
41,"weight, svm, matrix","the only class-specific computations are dot products between features and SVM weights and non-maximum suppression . The feature matrix is typically 2000 x 4096 x N, where N is the number of classes ."
42,"r-cnn, multi-core, cpu","R-CNN can scale to thousands of object classes without resorting to approximate techniques, such as hashing . Even if there were 100k classes, the resulting matrix multiplication takes only 10 seconds on a modern multi-core CPU . UVA system, due to its high-dimensional features, would be two"
45,"image-level, pre-training, cnn, annotations",We discriminatively pre-trained the CNN on a large auxiliary dataset using image-level annotations only . Pre-training was performed using the open source Caffe CNN library .
46,"domain-specific, imagenet, gradient, descent, stochastic, fine-tuning, specific","We continue stochastic gradient descent training of the CNN parameters using only warped region proposals . For VOC, N = 20 and for ILSVRC2013, IL = 200 ."
48,"iou, sgd, positive, windows, background","We start SGD at a learning rate of 0.001 . In each SGD iteration, we uniformly sample 32 positive windows and 96 background windows to construct a mini-batch of size 128 ."
49,"iou, classifier, binary, overlap, threshold","Consider training a binary classifier to detect cars . It's clear that an image region tightly enclosing a car should be a positive example . We resolve this issue with an IoU overlap threshold, below which regions are defined as negatives ."
53,"practices, 2007, 2012, voc, pascal, trainval, dataset, best",PASCAL VOC best practices validated all design decisions and hyperparameters on the VOC 2007 dataset . We fine-tuned the CNN on VOC 2012 train and optimized our detection SVMs .
54,"system, uva, dpm","We compare our method against four strong baselines, including SegDPM . The most germane comparison is to the UVA system from Uijlings et al."
55,"descriptors, sim-ilar, extended, rgb-sift, performance, opponentsift","We achieve a large improvement in mAP, from 35.1% to 53.7% . Our method achieves similar performance on VOC 2011/12 test ."
58,"r-cnn, of, 2013, competition, overfeat, ilsvrc, quality","Figure 3 compares R-CNN to the entries in the ILSVRC 2013 competition and to the post-competition OverFeat result . To give a sense of the AP distribution over classes, box plots are presented and a table of perclass APs follows ."
62,"unit, aver-aging, network, visual, modes","The idea is to single out a particular unit in the network . We compute the unit's activations on a large set of held-out region proposals . Our method lets the selected unit ""speak for itself"" by showing exactly which inputs it fires on ."
64,"aerobike, test",VOC 2010 test aero bike bird boat bottle bus car cat chair COW table dog horse mbike person plant sheep sofa train tv mAP DPM v5  49.2 53.8 13.1 15.3 35.5 53.4 49.7 27.0 17.2 28.8 14.7 17.8 46.4 5
75,"pool5, layer, unit, combustion, network",layer pool5 is the maxpooled output of the network's fifth and final convolutional layer . Each pool5 unit has a receptive field of 195 x 195 pixels in the original 227 x 227 pixels input .
76,"cnn, representation, network, windows","Figure 4 shows the top 16 activations for a pool5 unit from a CNN . Six of the 256 functionally unique units are visualized . In the second row, we see a unit that fires on dog faces and dot arrays ."
81,"power, cnn, computing, layer-by-layer, representational, performance","29%, or about 16.8 million, of the CNN's parameters can be removed without degrading mAP . More surprising is that removing both fc7 and fC6 produces quite good results even though pool5 features are computed using only 6% . This finding suggests potential utility in computing "
84,"imagenet, fine-tuning, map, trainval",fine-tuning increases mAP by 8.0 percentage points to 54.2% . Most of the improvement is gained from learning domain-specific non-linear classifiers .
86,"hog, sketch, token, st, features, dpm","The first DPM feature learning method, DPM ST , augments HOG features with histograms of ""sketch token"" probabilities . Sketch token probabilities are computed at each pixel by a random forest ."
88,"hog, dpm, hsc",All R-CNN variants strongly outperform the three DPM baselines . The combination of HOG and sketch tokens yields 2.5 mAP points over HOG alone .
90,"2014, ilsvrc, network, architecture","In Table 3 we show results on VOC 2007 test using the 16-layer deep network recently proposed by Simonyan and Zisserman . The network has a homogeneous structure consisting of 13 layers of 3 x 3 convolution kernels, with five max pooling layers interspersed, and topped with"
91,"r-cnn, model, t-net, zoo, network, weights, o-net, caffe","To use O-Net in R-CNN, we downloaded the publicly available pre-trained network weights for the VGG_ILSVRC_1 6_layers model from the Caffe Model Zoo . 1 We then fine-tuned the network using the same protocol as we used for T-Net ."
93,"finer, detection, analysis, details, dpm, tool","We applied the excellent detection analysis tool from Hoiem et al. to reveal our method's error modes, understand how fine-tuning changes them, and to see how our error types compare with DPM . A full summary of the analysis tool is beyond the scope of this paper and we encourage readers to consult"
95,"bounding-box, window, errors, regression, localization","Based on the error analysis, we implemented a simple method to reduce localization errors . Inspired by the bounding-box regression employed in DPM , we train a linear regression model to predict a new detection window given the pool5 features for a selective search region proposal . Results in Table 1, Table 2, and Figure"
97,"detection, qualitative, val2, ilsvrc2013, set",Qualitative detection results on ILSVRC2013 are presented in Figure 8 and Figure 9 at the end of the paper . Each image was sampled randomly from the val2 set and all detections from all detectors with a precision greater than 0.5 are shown . Note that these are not curated and give 
108,"val, and, test, splits, ilsvrc, distribution, image",val and test splits are drawn from the same image distribution . These images are scene-like and similar in complexity to PASCAL VOC images . In each image all instances from all 200 classes are labeled with bounding boxes .
109,"r-cnn, hard, mining, negative, training","The nature of these splits presents a number of choices for training R-CNN . The train images cannot be used for hard negative mining . Also, the train images have different statistics than val and test ."
110,"candidate, val, validative, sets, splits, examples","our general strategy is to rely heavily on the val set and use some of the train images as an auxiliary source of positive examples . To use val for both training and validation, we split it into roughly equally sized ""val1 , , and ""val2 , "" sets ."
112,"images, val, class, imbalance",class imbalance was selected . Each candidate split was generated by clustering val images using class counts as features . The particular split used here has a maximum relative imbalance of 11% .
114,"search, resolution, selective, ilsvrc, image","Selective search was run in ""fast mode"" on each image in val1, val2 and test . On val, selective search resulted in an average of 2403 region proposals per image . This recall is notably lower than in PASCAL ."
116,"images, and, boxes, data, training","For training data, we formed a set of images and boxes that includes all selective search and ground-truth boxes from val1 together with up to N Ground-Truth boxes per class from train ."
117,"bounding-box, regressor, svm, cnn, bounding-truth, box, training",CNN fine-tuning was run for 50k SGD iteration on val1 +trainN using the exact same settings as PASCAL . Fine-tuneing on a single NVIDIA Tesla K20 took 13 hours using Caffe . Hard negative mining was performed on randomly selected subset of 
121,"val2, bounding-box, regression, ilsvrc, set","All system hyperparameters were fixed at the same values used for PASCAL . After selecting the best choices on val2, we submitted exactly two result files to the ILSVRC2013 evaluation server . The first submission was without bounding-box regression and the second was with boundingbox regression ."
123,"map, bounding-box, data, regression, training, fine-tuning","Table 4 shows an ablation study of the effects of different amounts of training data, fine-tuning, and boundingbox regression . The first result, 20.9%, is what R-CNN achieves using a CNN pre-trained on the ILSVRC2012 classification dataset . Expanding the training"
129,"r-cnn, speeding, speed","OverFeat has a significant speed advantage over R-CNN: it is about 9x faster, based on a figure of 2 seconds per image quoted from . This speed comes from the fact that overFeat's sliding windows are not warped at the image level . Sharing is implemented by running the entire network"
131,"system, voc, cpmc, tation, pascal, semantic, segmen-, segmentation","Region classification is a standard technique for semantic segmentation . O2P uses CPMC to generate 150 region proposals per image and then predicts the quality of each region, for each class, using support vector regression . Farabet et al. recently demonstrated good results on several dense scene labeling datasets using"
134,"shape, cnn, gion, re-, features, background","gion's shape and computes CNN features directly on the warped window . However, these features ignore the non-rectangular shape of the region . The third strategy simply concatenates the full and fg features ."
137,"full+fg, validation, o2p, set","Table 5 shows a summary of our results on the VOC 2011 validation set compared with O2P . The fg strategy slightly outperforms full, indicating that the masked region shape provides a stronger signal, matching our intuition . Full+fg achieves an average accuracy of 47.9%"
138,"voc, full+fg, accuracy, test, 2011, set, segmentation",In Table 6 we present results on the VOC 2011 test set . Our method achieves the highest segmentation accuracy for 11 out of 21 categories .
144,"data-scarce, cnn, neural, vision, network, network-works, convolutional",The first is to apply high-capacity convolutional neural networks to bottom-up regions proposals . the second is a paradigm for training large CNNs when labeled training data is scarce .
153,"content, transformation, cnn, warp, size, input, image",Figure 7 column shows this transformation . The second method anisotropically scales each object proposal to the CNN input size . A variant on this method excludes the image content that surrounds the original object proposal.
154,"padding, context, cnn, image","The amount of context padding is defined as a border size around the original object proposal in the transformed input coordinate frame . In all methods, if the source rectangle extends beyond the image, the missing data is replaced with the image mean . Obviously more alternatives are possible, including replication instead of mean padding ."
157,"com, svm, cnn, combustion","The first is: Why are positive and negative examples defined differently for fine-tuning the CNN versus training the object detection SVMs? To review the definitions briefly, we map each object proposal to the ground-truth instance with which it has maximum IoU overlap . All other proposals are labeled ""back"
158,"imagenet, svm, positive, definition, example","Historically speaking, we arrived at these definitions because we started by training SVMs on features computed by the ImageNet pre-trained CNN . When we started using fine-tuning, we initially used the same positive and negative example definition as we were using for SVM training . However, we found that results"
159,"fine-tuning, data, positive, example","Our current scheme introduces many ""jittered"" examples . This expands the number of positive examples by approximately 30x . We conjecture that this large set is needed when fine-tuning the entire network ."
160,"classifier, fine-tuning, regression, softmax",We tried this and found that performance on VOC 2007 dropped from 54.2% to 50.9% mAP . This performance drop likely arises from a combination of factors .
164,"bounding-box, performance, regression, localization","We use a simple bounding-box regression stage to improve localization performance . After scoring each selective search proposal with a class-specific detection SVM, we predict a new bounding box for the detection . The primary difference between the two approaches is that here we regress from features computed by the CNN,"
165,"bounding, algorithm, proposal, box, ground-truth, training, pi","The input to our training algorithm is a set of N training pairs i=1,...,N . Each ground-truth bounding box G is specified in the same way: G = ."
166,"bounding, log-space, translation, box","The first two specify a scale-invariant translation of the center of P's bounding box . The second two specify log-space translations of the width and height of P . After learning these functions, we can transform an input proposal P into a predicted ground-truth box G ."
171,"bounding-box, validation, regression, set",The first is that regularization is important: we set  = 1000 based on a validation set . The second issue is that care must be taken when selecting which training pairs to use . We only learn from a proposal P if it is nearby at least one ground-truth box .
179,"2012, pas-cal, whole-image, classification, ilsvrc, image",our findings may be useful to researchers who are interested in using ILSVRC 2012 as training data for the PASCAL image classification task .
182,"flickr, matching, gist, nearest-neighbor, id","Euclidean distance nearest-neighbor matching of GIST descriptors revealed 38 near-duplicate images . The matches tend to vary slightly in JPEG compression level and resolution . Based on GIST matches, 1.5% of VOC 2012 test images are in ILSVRC 2012 trainval."
194,"image, net, cvpr, windows","TPAMI, 2012. 2, 3 D. Cire an, A. Giusti, L. Gambardella, and J. Schmidhuber. Mitosis detection in breast cancer histology images with deep neural networks . In CVPR, 2013. 3 J. Deng, W. Dong, R."
195,"c, cvpr","IJCV, 2010. 1 4 C. Farabet, C. Couprie, L. Najman, and D. Ramanan. Object detection with discriminatively trained part based models . In CVPR, 2013. 4, 5 K. Fukushima. Neocognitron: A self"
214,"detection, object, view-based, visual, face","In CVPR, 2013. 1, 2, 4, 10 P. Sermanet, K. Kavukcuoglu, S. Chintala, and Y. LeCun. OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks . IEE Proc on Vision"
