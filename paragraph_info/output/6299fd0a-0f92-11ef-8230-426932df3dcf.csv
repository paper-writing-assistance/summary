element_idx,summarized_text,keywords
4,"semantic segmentation methods adopt a fully-convolutional network with an encoderdecoder architecture . The encoder progressively reduces the spatial resolution and learns more abstract/semantic visual concepts with larger receptive fields . Since context modeling is critical for segmentation, the latest efforts have been focused","sequence, to, segmentation, fcn, fully-convolutional, network, semantic, prediction"
8,"feature representation learning is arguably the most important model component . The encoder, like most other CNNs designed for image understanding, consists of stacked convolution layers . Due to computational cost, the resolution of feature maps is reduced progressively .","concept, understanding, visual, image, cnn"
9,"a number of approaches have been introduced recently . One is to directly manipulate the convolution operation . This includes large kernel sizes , atrous convolutions , and image/feature pyramids . The other approach is to integrate attention modules into the FCN architecture .","segmenta-, model, fcn, semantic, tion, attention-alone, attention, module"
13,"In this paper, we propose to replace the stacked convolution layers based encoder with gradually reduced spatial resolution with a pure transformer . This transformer-alone encoder treats an input image as a sequence of image patches represented by learned patch embedding, and transforms the sequence with global self-attention modeling .","segmentation, semantic, model, trans-former"
14,a pure vision transformer or ViT has shown to be effective for image classification tasks . It provides direct evidence that the traditional stacked convolution layer design can be challenged and image features do not necessarily need to be learned progressively from local to global context by reducing spatial resolution .,"spatial, pure, task, natural, language, location, processing, sensitive, transformer"
15,"We reformulate the image semantic segmentation problem from a sequence-to-sequence learning perspective . As an instantiation, we exploit the transformer framework to implement our fully attentive feature representation encoder by sequentializing images . Extensive experiments show that our SETR models can learn superior feature representations as ","problem, model, feature, segmentation, fcn, attentive, semantic, representation"
17,"Semantic image segmentation has been significantly boosted with the development of deep neural networks . By removing fully connected layers, the fully convolutional network is able to achieve pixel-wise predictions .","convolutional, segmentation, fcn, fully, network, semantic"
18,DeepLab and Dilation introduce the dilated convolution . The latter proposes the PPM module to obtain different region's contextual information . Decomposed large kernels are also used for context capturing .,"spatial, dilated, modeling, context, convolution, fcn, attention"
19,Non-local network appends transformer style attention onto the convolutional backbone . LRNet and standalone networks explore local self-attention . Axial-Attention decomposes the global spatial attention into two separate axial attentions .,"machine, self-attention, convolution, translation"
23,STTR and LSTR adopt transformer for disparity estimation and lane shape prediction respectively. ViT is the first work to show that a pure transformer based image classification model can achieve the state-of-the-art .,"head, pure, transformer, detection"
24,"The most related work is which also leverages attention for image segmentation . However, there are several key differences . First, though convolution is completely removed in as in our SETR, their model still follows the conventional FCN design in that spatial resolution of feature maps is reduced progressively . Second, to maximize the s","image, fcn, self-attention, segmentation"
28,The input of subsequent layer i is a three-dimensional tensor sized h x w . d is the feature/channel dimension of feature maps . Locations are computed based on the locations of all lower layers they are connected to via layerby-layer convolutions .,"size, receptive, image, fcn, architecture, fields"
29,a number of state-of-the-art methods suggest that combing FCN with attention mechanism is a more effective strategy for learning long-range contextual information . These methods limit attention learning to higher layers with smaller input sizes alone due to its quadratic complexity w.r.t. the pixel number of feature,"methods, mechanism, state-of-the-art, attention"
32,Image to sequence SETR follows the same input-output structure as in NLP . There thus exists a mismatch between 2D image and 1D sequence .,"nlp, sequence, structure, input-output"
33,"A simple way for image sequentialization is to flatten the image pixel values into a 1D vector with size of 3HW . Given the quadratic model complexity of Transformer, it is not possible that such high-dimensional vectors can be handled in both space and time .","image, sequentialization"
35,To obtain the 256 image x E RHxWx3 H W into a grid of x patches uni16 16 formly . By further mapping each vectorized patch p into the latent Cdimensional embedding space using a linear projection function f: p  e E ,"image, hw, embedding, space, x"
36,"Transformer Given the 1D embedding sequence E as input, a pure transformer based encoder is employed to learn feature representations . At each layer l, the input to self-attention is in a triplet of computed from the input Zl-1 E RLxC as:","multi-head, fcn, perceptron, self-attention, multilayer, transformer"
42,"to evaluate the effectiveness of SETR's encoder feature representations Z, we introduce three different decoder designs to perform pixel-level segmentation . We need to reshape the encoder's features, Z, from a 2D shape of HW C to a standard 3D feature map","setr, segmentation, pixel-level"
43,"Naive upsampling This naive decoder first projects the transformer feature ZLe to the dimension of category number . After that, we simply upsample the output to the full image resolution .","cityscape, feature, naive, upsampling, transformer"
44,"Progressive UPsampling Instead of one-step upscaling, we consider a progressive strategy that alternates conv layers . To maximize the adversarial effect, we restrict upsamping to 2x . We denote our model as SETR-PUP .","progressive, pup, strategy, upsampling"
52,"In each stream, we first reshape the encoder's feature Zl from a 2D shape of HW C to a x 256 H W 3-layer network is applied with the feature channels halved at the first and third layers respectively . The spatial resolution upscaled 4x by","size, kernel, design, addition, element-wise, 3, aggregation"
61,"We set batch size 16 and the total iteration to 160,000 and 80,000 for the experiments on ADE20K and Pascal Context . We adopt a polynomial learning rate decay schedule and employ SGD as the optimizer . Momentum and weight decay are set to 0.9 and 0 respectively for all","augmentation, sch, data, training"
63,"Multi-scale test We use the default settings of mmsegmentation . Specifically, the input image is first scaled to a uniform size . Sliding window is adopted for test .","test, window, multi-scale, sliding"
71,"SETR variants Three variants of our model with different decoder designs . We denote SETR-Naive-Base as the model utilizing ""T-Large""","setr, setr-pup, setr-, setr-mla, setr-naive-base"
78,Pre-training We use the pre-trained weights provided by ViT or DeiT to initialize all the transformer layers and the input linear projection layer in our model . All the layers without pre-training are randomly initialized.,"input, projection, pre-training, linear, layer, deit"
88,"Table 2 and 3 show ablation studies on different variants of SETR on various training schedules . Pre-training on different data, comparison with Hybrid, compare to FCN with different pre-training . Experiments on ADE20K also follow the single scale test protocol .","validation, 2, table, and, cityscapes, set, 3"
92,"PUP achieves the best performance among all the variants on Cityscapes . The variants using ""T-Large"" are superior to the variant SETRNaive . It suggests that FCN encoder design can be replaced in semantic segmentation . Randomly initialized SETR-PUP only gives","segmentation, semantic, fpn, cityscapes"
98,"To study the power of pre-training and further verify the effectiveness of our proposed approach, we conduct the ablation study on the Pre-training strategy in Table 3 . For fair comparison with the FCN baseline, we pre-train a ResNet-101 on Imagenet-21k with a classification task and then adopt the pre","ablation, task, segmentation, imagenet-21k, pre-training, study, semantic"
100,"Results on ADE20K Table 4 presents our results on the more challenging dataset . Our SETRMLA achieves superior mIoU of 48.64% . When multi-scale inference is adopted, our method achieves a new state of the art .","inference, dilated, fcn, ade20k, multiscale"
102,ResNet-101 backbone achieves a mloU of 45.74% . SETRMLA further improves the performance to 55.83% . Figure 3 gives some qualitative results of SETR and dilated FCN .,"semantical, apcnet, meaningful, attention, maps, regions"
103,"Results on Cityscapes Tables 6 and 7 show the comparative results on the validation and test set respectively . We can see that our model SETR-PUP is superior to FCN baselines, and FCN plus attention based approaches, such as Non-local and CCNet . On this dataset we can now","validation, based, approaches, attention, cityscapes, set"
105,"In this work, we have presented an alternative perspective for semantic segmentation by introducing a sequenceto-sequence prediction framework . In contrast to existing FCN based methods that enlarge the receptive field typically with dilated convolutions and attention modules at the component level, we made ","ade20, segmentation, semantic, modules, attention, models"
111,"Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs . TPAMI, 2018. 1 Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L. Yuille.","image, segmentation, atrous, convolution, semantic"
112,"In NAACL-HLT, 2019. 2 Henghui Ding, Xudong Jiang, Bing Shuai, Ai Qun Liu, and Gang Wang. Semantic correlation promoted shape-variant context for segmentation . In CVPR, 2019. 2, 3, 6, 8 Junjun He,","image, segmentation, recognition, semantic, axial, attention"
114,"Xia Li, Zhisheng Zhong, Jianlong Wu, Yibo Yang, Zhouchen Lin, and Hong Liu. Expectation-maximization attention networks for semantic segmentation. In CVPR, 2019. 6 Zhaoshuo Li, Xingtong Liu, Francis X Creight","convolutional, segmentation, axial-deeplab, semantic, networks"
115,"In CVPR, 2018. 1, 7 Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. XLNet: Generalized autoregressive pretraining for language understanding. In NeurIPS, 2019.","context, segmentation, network, semantic, ade20k, attention, graph, dataset"
