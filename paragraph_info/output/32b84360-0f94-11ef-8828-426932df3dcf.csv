element_idx,keywords,summarized_text
4,"bounding, class, boxes, probabilities, network, work","Prior work on object detection repurposes classifiers to perform detection . Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities in one evaluation . Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance"
5,"detection, system, natural, state-of-the-art, architecture, image","Our base YOLO model processes images in real-time at 45 frames per second . A smaller version of the network, Fast YoLO, processes an astounding 155 frames . Compared to state-of-the-art detection systems, yOLO makes more localization errors ."
7,"detection, system, object, driving, human, visual","human visual system is fast and accurate, allowing us to perform complex tasks like driving with little conscious thought . Fast, accurate algorithms for object detection would allow computers to drive cars without specialized sensors ."
12,"bounding, boxes, post-processing","post-processing is used to refine the bounding boxes, eliminate duplicate detections, and rescore them based on other objects in the scene ."
15,"detection, problem, frame, regression, yolo",YOLO is extremely fast. Since we frame detection as a regression problem we don't need a complex pipeline . Our base network runs at 45 frames per second with no batch processing on a Titan X GPU and a fast version runs at more than 150 fps .
20,"background, patches, errors","Fast R-CNN, a top detection method, mistakes background patches in an image . YOLO makes less than half the number of background errors ."
25,"bounding, separate, box, network, yolo",We unify the components of object detection into a single neural network . Our network uses features from the entire image to predict each bounding box . It also predicts all bounding boxes across all classes for an image simultaneously .
27,"bounding, confidence, b, score, cell, grid, box, ground, truth",Each grid cell predicts B bounding boxes and confidence scores for those boxes . These confidence scores reflect how confident the model is that the box contains an object . Formally we define confidence as Pr * IOUtruth . Otherwise we want the confidence score to equal the intersection over union between the predicted box and the ground truth 
44,"imagenet, convolutional, layer, network",We pretrain our convolutional layers on the ImageNet 1000-class competition dataset . We train this network for approximately a week and achieve a single crop top-5 accuracy of 88% .
45,"detection, mation, infor-, network, visual",Ren et al. show that adding convolutional and connected layers to pretrained networks can improve performance . Detection often requires fine-grained visual information .
48,"instability, model",we use sum-squared error because it is easy to optimize . It weights localization error equally with classification error which may not be ideal . In every image many grid cells do not contain any object .
51,"bounding, cell, grid, box, multiple, truth","YOLO predicts multiple bounding boxes per grid cell . At training time we only want one bounding box predictor to be responsible . Each predictor gets better at predicting certain sizes, aspect ratios, or classes of object ."
69,"detection, object, computer, vision, features, robust",Object detection is a core problem in computer vision . Detection pipelines start by extracting robust features from input images . Classifiers or localizers are run either in sliding window fashion .
70,"bounding, approach, window, sliding, box, dpm","Deformable parts models use a sliding window approach to object detection . Our system replaces all disparate parts with a single convolutional neural network . Instead of static features, the network trains features in-line and optimizes them for the detection task ."
73,"r-cnn, spatial, proposals, cell, grid, constraints",YOLO shares some similarities with R-CNN . Each grid cell proposes potential bounding boxes and scores those boxes using convolutional features . Our system puts spatial constraints on the grid cell proposals .
78,"r-cnn, multibox, multi-box",Szegedy et al. train a convolutional neural network to predict regions of interest instead of using Selective Search . MultiBox can also perform single object detection by replacing the confidence prediction with a single class prediction .
79,"performance, dpm, localization","Sermanet et al. train a convolutional neural network to perform localization . OverFeat optimizes for localization, not detection performance ."
81,"detection, grasp, grasps, multigrasp, regression",MultiGrasp only needs to predict a single graspable region for an image containing one object . YOLO predicts both bounding boxes and class probabilities for multiple objects of multiple classes .
83,"fem, variants, r-cnn",YOLO can be used to rescore Fast R-CNN detections . We also present VOC 2012 results and compare mAP to state-of-the-art methods .
85,"detection, ing, mak-, pipelines, standard",We compare YOLO to their GPU implementation of DPM which runs either at 30Hz or 100Hz . The other efforts don't reach the real-time milestone we also compare their relative mAP and speed to examine the accuracy-performance tradeoffs available in object detection systems .
94,"r-cnn, zeiler-fer, faster, zeiler-fergus","Faster R-CNN replaces selective search with a neural network to propose bounding boxes, similar to Szegedy et al. In our tests, their most accurate model achieves 7 fps while a smaller, less accurate one runs at 18 . The ZeilerFergus Fast"
116,"vgg-16, yolo, voc, 2012, test, set","On the VOC 2012 test set, YOLO scores 57.9% mAP . This is lower than the current state of the art, closer to the original R-CNN using VGG-16 ."
124,"artwork, natural, image","YOLO models the size and shape of objects, as well as relationships between objects and where objects commonly appear . Artwork and natural images are very different on a pixel level ."
141,"detection, deep, object, networks, neural, cvpr, semantic, segmentation","In Computer VisionECCV 2008, pages 2-15. Springer, 2008. 4 L. Bourdev and J. Malik. Poselets: Body part detectors trained using 3d human pose annotations . IEEE Computer Society Conference on, volume 1, pages 886-893. IEEE, 2005. 4, 8 T. Dean, M"
142,"imagenet, recognition, communication, visual","In Computer VisionECCV 2014, pages 297-312. Springer, 2014. 7 K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling in deep convolutional networks for visual recognition ."
143,"detection, object, computer, vision, recognition","W. Liu, Y. Jia, P. Sermanet, S. Reed and D. Anguelov . International journal of computer vision, 4:34-47, 2001. 4 P. Viola and M. J. Jones. Robust real-time object detection ."
