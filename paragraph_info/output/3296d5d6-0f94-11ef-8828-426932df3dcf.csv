element_idx,keywords,summarized_text
6,"mammo, th, math, problem-, mammoth-7b, model, mammoth, mammoth-34b","MAmmo TH models are trained on MathInstruct, our meticulously curated instruction tuning dataset . It is compiled from 13 math datasets with intermediate rationales . The hybrid of CoT and PoT also unleashes the potential of tool use ."
14,"open-source, reasoning, mathematical, models, llms","despite recent advances in this field, a noticeable gap exists between closed-source and open-source LLMs-closed-source models like GPT-4 , PaLM-2 , and Claude 2 dominate popular mathematical reasoning benchmarks such as GSM8K and MATH ."
15,gis,Current efforts to bridge this gap are twofold . Continued pre-training like Galactica and MINERVA . This approach improves a model's general scientific reasoning capability .
16,"capabilities, computation, precision, reasoning, mathematical","Existing methods primarily focus on Chain-of- Thought approaches to solve math problems through step-by-step natural language descriptions . This approach excels in its generality to cover most math subjects but struggles with computation precision, and complex mathematical or algorithmic reasoning procedures . PoT falls short in dealing with more abstract reasoning scenarios"
17,"ruct, mathinst",MathInstruct is based on seven existing math rationale datasets and six newly-curated datasets . We use MathInst ruct to fine-tune Llama models of different scales ranging from 7B to 70B .
18,"math, sets, test, mammoth, ood, open-source","We evaluate MAmmoTH on a spectrum of datasets, including in-domain test setsGSM8K , MATH , AQuA-RAT , NumGLUE . On the popular competition-level MATH dataset, our 7B model can beat WizardMath by 3.5x ."
19,"mammo, th-coder, th-","We present Math Instruct, a high-quality math instruction tuning dataset . From the data engineering perspective, we investigate the impact of various data sources and input-output formats through training and evaluating over 50 different models and baselines ."
26,"com-, plex, multi-hop, reasoning, mathematical",CoT prompting encourages LLMs to solve problems incrementally on a scratchpad . This approach enhances both accuracy and explainability in mathematical reasoning . Key breakthroughs have been made through PoT prompts and CoT .
29,"modelling, complexity, level, knowledge, gpt-4, gps, mathematical","We aim for a broad representation of different math fields and complexity levels in our dataset . This ensures exposure to a diverse set of mathematical knowledge, fostering versatility in our models . To rectify this, we use GPT-4 to synthesize CoT rationales for questions in TheoremQA and"
32,"gpt-4, hplc, ration","CoT and PoT Rationales: Contrary to previous work that focus on CoT, our dataset strategically combines both. This integration enhances the dataset's versatility, catering to different mathematical problem-solving approaches . To fill the gap, we use GPT-4 to supplement the PoT rationales for selected dataset"
33,"of, dataset, fields, core, quality, mathematical, instruction","Our instruction dataset, detailed in Table 1, encompasses 260K pairs . This dataset covers a wide range of core mathematical fields . It offers diversity in both language and difficulty levels ."
35,"thinst, alpaca-like, ruct, instruction, dataset, ma, mathinst","Unify all subsets in our MathInst ruct to conform to the structure of an Alpaca-like instruction dataset . We use a learning rate of 2e-5 for the 7B and 13B models, and 1e-5 in the 34B and 70B models ."
38,"commonsense, reasoning, mathematic","Our preliminary evaluation reveals that PoT generally outperforms CoT . However, PoT struggles with abstract reasoning scenarios . To further combine the power of both approaches, we introduce a simple hybrid decoding strategy: The model first attempts PoT prompting ."
42,mmlu-mat,"For the out-of-domain datasets, we consider GSM8K , MATH , AQuA-RAT , and NumGLUE . The selection of evaluation datasets includes math problems from elementary, high school, and college levels . Some of the datasets even include formal logic and commonsense"
49,"gps, gps8k","Llama Base: For the base models, we choose Code-Lama , CodeT5+ and CodeGen . We include Orca-Platypus , Vicuna-1.5 , Tulu , Platypus-2 and Guanaco ."
50,"code, mammo, th-coder, model, mammoth","All the 'Code Model' use PoT prompting to maximize performance . For GSM8K, MATH, AQuA, and NumGLUE, we will evaluate both 8-shot in-context-learning and zero-shot setups to report the highest score ."
52,"mammo, th-coder-34b","We report our in-domain and out-of-domain results in Table 3 and Table 4 respectively . In general, the performance gain for OOD datasets is more significant than IND datasets . These results show us the potential of our models as a mathematical generalist . On several datasets, MAmmo "
57,math-sft,Table 3: The table compiles all the in-domain evaluation results . Results marked as 1 are copied from other papers . Math-SFT? means whether the model has been instruction-tuned on any math reasoning datasets.
63,"mammoth, sota, open-source","WizardMath's results are highly competitive on these two datasets . The dataset-specific training can be detrimental to OOD datasets like AQuA . In contrast, Platypus fine-tunes LLMs on a wide range of text and math reasoning datasets."
67,"3d, model","""Out-of-domain"" refers to the five datasets detailed in Table 2. Key insights include: 1) The SoTA model displays strong performance within its domains but struggles in OOD scenarios; 2) Diverse data sources in MathInstruct enable better math generalist model ."
68,"mammo, th-7b, th-70b",Table 4 shows that our main competitor for OOD datasets is Platypus . This demonstrates our models' remarkable generalizability to unseen math problems . MAmmo TH-7B also boosts the CoT performance of WizardMath-7B greatly .
69,"mammo, th-coder, th-","CodeLlama is consistently better than Llamama-2, especially on OOD datasets . MAmmo TH-Coder's average performance is actually higher than 5% . We believe CodeLama benefits greatly from the continuous code training of Code-Llaama ."
81,"mammo, th","We focus on five significant subsets: GSM8K, MATH, Camel, AQuA and NumGLUE . We conduct an experiment gradually adding each dataset into training and compare the performance with the one fine-tuned on the whole MathInstruct."
84,"hybrid, decoding","Hybrid Decoding improves performance on every test set . By default, we initially attempt the PoT decoding method for a given question . Ifit fails to generate an executable query, we then transition to the CoT method ."
86,"capabilities, mathematical, reasoning, llms","In this paper, we propose a novel math instruction tuning approach to activate open-source LLMs' mathematical reasoning capabilities . Through a comprehensive study, we show that our models can outperform the SoTA performance at different scales by a huge margin . Our instruction tuning dataset contains 260K samples ."
90,"problem, math, aclanthology, word, operation-based, formalisms","MathQA: Towards interpretable math word problem solving with operation-based formalism . In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 ."
106,"solv-, problem, mathematical, ing, neurips, datasets","Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt."
122,"mathematical, tasks, reasoning, aclanthology",NumGLUE: A suite of fundamental yet challenging mathematical reasoning tasks . In Proceedings of the 60th Annual Meeting of the Associationfor Computational Linguistics . doi: 10.18653/v1/2022.acl-long.246.
135,"multitask, enables, iclr, training, 2022, prompted","Multitask prompted training enables zero-shot task generalization . In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022 ."
142,"prompting, acl, anthology, acl-long","Association for Computational Linguistics, 2023a . doi: 10.18653/ v1/2023.acl-long.153 ."
150,"nlp, empirical, natural, instructions, language, processing","Super-NaturalInstructions: Generalization via declarative instructions on 1600+ NLP tasks . In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 5085-5109, 2022b."
179,"mathematical, addsub, literature, reasoning, dataset","Our work builds upon the existing mathematical reasoning literature . Early on, mathematical reasoning is mostly focused on solving synthetic basic math problems like AddSub and other arithmetic reasoning datasets ."
181,"ing, chain-of-, prompt-, plan-and-solve, self-evaluation, thought, llms",ReAct Yao et al. proposes to leverage external tools like search engines to enhance LLM reasoning skills . Self-critic and self-eval both adopt selfevaluation to enhance the robustness of the generated program . Plan-and-solve instead adopts more detailed planning instructions to help LLM
183,"gps-, (gps-v2), gps, gps-v2","Instruction tuning is part of a line of work designed to ""align"" language models with more useful objectives and human preferences . Since 2021, CrossFit and NaturalInstruction , FLAN and T0 are amongst the first wave of instruction tuning effort to understand LLMs' generalization capabilities ."
187,"questions, pot, cot, python","We compare our PoT results VS. CoT results in Figure 3, Figure 4 and Figure 5 . In the second and third case, we can further see the advantages of PoT over CoT by utilizing external tools and Python packages ."
196,"control, value, isosceles, triangle","Answer Choices: 20  x = + 16)/ satisfies . We substitute the smallest value ofn, which is 36, and get 42 . CoT Select the best translation into predicate logic. Some CEO is wealthier than everyone ."
205,"mammo, th, datasets, rationale, mathematical, models","MAmmo TH models may exhibit limitations when faced with problems outside their primary domain of expertise . Also, they have not been trained with proof-type problems . In the future, we would like to expand the models' skill set to cover more fields ."
206,"of, cleanliness, our, purity, training, mammoth","MAmmoTH models could be misused for malicious purposes, such as spreading misinformation or probing sensitive topics . Developers should conduct safety testing and tuning tailored to their specific applications . It is unlikely but not impossible that some inappropriate questions slipped through the curation process ."
207,"mammoth, reasoning, robustness","Recent work identifies ""sycophancy"" and ""Clever Hans effect"" in reasoning . Potential methods to improve the models' reasoning robustness could involve the exploration of synthetic data intervention methods ."
