element_idx,keywords,summarized_text
3,"fpg, fpgn",Abstract-State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations . Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks . The RPN is a fully convolutional network that simultaneously predicts object bounds and object
7,"r-cnn, networks, neural, region-based, convolutional","Recent advances in object detection are driven by the success of region proposal methods and region-based convolutional neural networks . The latest incarnation, Fast R-CNN , achieves near real-time rates using very deep networks when ignoring the time spent on region proposals ."
8,"engineered, proposal, features, low-level, quality","Selective Search is an order of magnitude slower, at 2 seconds per image in a CPU implementation . EdgeBoxes currently provides the best tradeoff between proposal quality and speed ."
9,"facebook, group, computing, microsoft, research, visual, s., ren, ai","S. Ren is with University of Science and Technology of China, Hefei, China . The majority of this work was done when R. Girshick was with Microsoft Research ."
10,"computation, cpu, cnns, region-based, gpu","fast region-based CNNs take advantage of GPUs, while the region proposal methods used in research are implemented on the CPU . re-implementation ignores the down-stream detection network and therefore misses important opportunities for sharing computation ."
11,"detection, computation, object, networks, proposal, state-of-the-art, network","In this paper, we show that an algorithmic changecomputing proposals with a deep convolutional neural network-leads to an elegant and effective solution where proposal computation is nearly cost-free given the detection network's computation . By sharing convolutions at test-time, the marginal cost for computing proposals is"
12,"fnn, features, region-based, detectors, convolutional",Convolutional feature maps used by region-based detectors can also be used for generating region proposals . We construct an RPN by adding a few additional convolutional layers that simultaneously regress region bounds and objectness scores at each location on a regular grid .
18,"of, images, aspect, ratios, pyramids, filters","""anchor"" boxes serve as references at multiple scales and aspect ratios . Our scheme can be thought of as pyramid of regression references . This model performs well when trained and tested using single scale images ."
20,"detection, voc, pascal, benchmarks, rbgirshick",Our method waives nearly all computational burdens of Selective Search at test-time . We also report results on the MS COCO dataset . Code has been made publicly available at https : / github  com/ shaoqingren/ faster_ rcnn .
24,"r-cnn, coco, mentation, seg-, ilsvrc","Faster R-CNN and RPN are the basis of several 1st-place entries in the tracks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation . These results suggest that our method is not only a cost-efficient solution for practical usage, but also an effective way of"
26,"comparison, in, object, proposal, windows, objectness",Object Proposals. There is a large literature on object proposal methods . Widely used object proposals methods include those based on grouping super-pixels and those on sliding windows .
27,"detection, deep, bounding, object, boxes, networks","The R-CNN method trains CNNs end-to-end to classify the proposal regions into object categories or background . In the OverFeat method , a fully-connected layer is trained to predict the box coordinates for the localization task that assumes a single object ."
32,"method, deepmask, crop, class-specific, multiple, large, objects, image",MultiBox methods generate region proposals from a network whose last fully-connected layer simultaneously predicts multiple class-agnostic boxes . MultiBox does not share features between the proposal and detection networks . The DeepMask method is developed for learning segmentation proposals .
33,"convolutional, convolution, accuracy, features, shared","Shared computation of convolutions has been attracting increasing attention for efficient, yet accurate, visual recognition . OverFeat paper computes convolutional features from an image pyramid for classification, localization, and detection ."
38,"object, region, proposals, rpn, proposal, network, f-cnn, rectangular","A Region Proposal Network takes an image as input and outputs a set of rectangular object proposals, each with an objectness score . We model this process with a fully convolutional network . In our experiments, we investigate the Zeiler and Fergus model ."
39,"map, spatial, feature, locations, window, sliding, convolutional",This small network takes as input an n x n spatial window of the input convolutional feature map . Each sliding window is mapped to a lower-dimensional feature . This feature is fed into two sibling fully-connected layers .
41,"k, proposals, boxes, reference",the reg layer has 4k outputs encoding the coordinates of k boxes . The cls layer outputs 2k scores that estimate probability of object or not object for each proposal4. The k proposals are parameterized relative to k reference boxes.
48,"invariant, multibox, translation, property, method","k-means generates 800 anchors, which are not translation invariant . MultiBox does not guarantee that the same proposal is generated if an object is translated ."
49,"translation-invariant, multibox, overfitting, property",MultiBox has a x 800-dimensional fully-connected output layer . We expect our method to have less risk of overfitting on small datasets .
53,"feature, aspect, ratios, predictions, image/, pyramids, multi-scale","The first way is based on image/ feature pyramids . The second way is to use sliding windows of multiple scales on feature maps . For example, in DPM , models of different aspect ratios are trained separately ."
54,"anchor-based, scales, multiple, method",Our method classifies and regresses bounding boxes with reference to anchor boxes of multiple scales and aspect ratios . It only relies on images and feature maps of a single scale .
59,"ground-truth, box, label, positive",A single ground-truth box may assign positive labels to multiple anchors . In some rare cases the second condition may find no positive sample . Anchors that are neither positive nor negative do not contribute to the training objective .
61,"robust, lreg, loss, regression","The ground-truth label p* is 1 if the anchor is positive, and is 0 if it is negative . ti is a vector representing the 4 parameterized coordinates of the predicted bounding box . The classification loss Lcls is log loss over two classes ."
62,"balancing, reg, nreg, parameter, ncls, å…¥, pit, term",The two terms are normalized by Ncls and Nreg and weighted by a balancing parameter  . By default we set  = 10 and thus both terms are roughly equal . The results are insensitive to the values of  in a wide range .
66,"roi-based, bounding-box, regression, based, roi, method","bounding-box regression is performed on features pooled from arbitrarily sized RoIs . In our formulation, the features used for regression are of the same spatial size on the feature maps . Each regressor is responsible for one scale and one aspect ratio ."
68,"gradient, descent, stochastic, image-centric, sampling, back-proagation, strategy","The RPN can be trained end-to-end by backpropagation and stochastic gradient descent . Each mini-batch arises from a single image that contains many positive and negative example anchors . Instead, we randomly sample 256 anchors in an image to compute the loss function of a mini-"
69,"imagenet, net, gaussian, vgg, zero-mean, distribution","We randomly initialize all new layers by drawing weights from a zero-mean Gaussian distribution with standard deviation 0.01 . All other layers are initialized by pretraining a model for ImageNet classification , as is standard practice ."
78,"joint, training, propagation, approximate, backward","In this solution, the RPN and Fast R-CNN networks are merged into one network during training as in Figure 2 . In each SGD iteration, the forward pass generates region proposals which are treated just like fixed, pre-computed proposals . This solution ignores the derivative w.r."
79,"bounding, non-approximate, boxes, joint, training, approximate","In a non-approximate joint training solution, we need an RoI pooling layer that is differentiable w.r.t. the box coordinates . This problem can be given by an ""RoI warping"" layer as developed in ."
80,"alternating, step-1, model, rpn, imagenet-pre-trained, training","In this paper, we adopt a pragmatic 4-step training algorithm . In the first step, we train the RPN as described in Section 3.1.3 . This network is initialized with an ImageNet-pre-trained model and fine-tuned end-to-end for the region proposal task."
81,"f-cnn, layers, convolutional, shared","fix the shared convolutional layers and only fine-tune the unique layers of Fast R-CNN . As such, both networks share the same alternating layers and form a unified network."
83,"multiscale, region, feature, extraction, both, proposal, pyramid, image",We train and test both region proposal and object detection networks on images of a single scale . We re-scale the images such that their shorter side is s = 600 pixels .
84,"ratios, aspect, anchor","For anchors, we use 3 scales with box areas of 1282, 2562, and 5122 pixels, and 3 aspect ratios of 1:1, 1:2, and 2:1 . As discussed, our solution does not need an image pyramid or filter pyramid to predict regions of multiple scales . Table 1 shows the learned average proposal size"
85,"boundaries, cross, anchors, training, cross-boundary, image","During training, we ignore all cross-boundary anchors so they do not contribute to the loss . For a typical 1000 x 600 image, there will be roughly 20000 anchors per image . If the boundary-crossing outliers are not ignored in training, they introduce large, difficult to correct error terms"
89,"nms, regions, proposals, rpn, proposal, redundancy","To reduce redundancy, we adopt non-maximum suppression on the proposal regions based on their cls scores . After NMS, we use the top-N ranked proposal regions for detection . We train Fast R-CNN using 2000 RPN proposals ."
92,"2007, voc, 2012, pascal, network, benchmark","This dataset consists of about 5k trainval images and 5k test images over 20 object categories . We also provide results on the PASCAL VOC 2012 benchmark for a few models . For the ImageNet pre-trained network, we use the ""fast"" version of ZF net ."
95,"detection, r-cnn, system, faster, fast","RPN with Fast R-CNN achieves competitive results, with an mAP of 59.9% while using up to 300 proposals8 . fewer proposals also reduce the region-wise fully-connected layers' cost ."
96,"proposal, quality, ablation","To investigate the behavior of RPNs as a proposal method, we conducted several ablation studies . First, we show the effect of sharing convolutional layers between the RPN and Fast R-CNN detection network . Using separate networks reduces the result slightly to 58.7% ."
109,"rpn, reg, outputs",RPN's cls and reg outputs turn off either of them at test-time . The mAP is nearly unchanged with N = 1000 .
113,"detection, 2007, voc, 2012, pascal, proposals, proposal","Table 3 shows the results of VGG-16 for both proposal and detection . Using RPN+VGG, the result is 68.5% for unshared features, slightly higher than the SS baseline . This is because the RPN is actively trained and benefits from better networks . For the feature-shared variant"
124,"vgg-16, fpg, svd","In Table 5 we summarize the running time of the entire object detection system . Fast R-CNN with VGG-16 takes in total 198ms for both proposal and detection . With the convolutional features shared, the RPN alone only takes 10ms computing the additional layers ."
126,"map, 3, aspect, ratios, regression, scales, references",the mAP drops by a considerable margin of 3-4% . Using just one anchor at each position is as good as using 3 scales with 3 aspect ratios .
129,"ss, rpn","In Figure 4, we show the results of using 300, 1000, and 2000 proposals . We compare with SS and EB, and the N proposals are the top-N ranked ones . The plots show that the RPN behaves gracefully when the number of proposals drops from 2000 to 300 ."
135,"detection, r-cnn, faster, region, cascade, proposals, proposal, features, region-wise","In OverFeat, the region-wise features come from a sliding window of one aspect ratio over a scale pyramid . These features are used to simultaneously determine the location and category of objects . In RPN, the features are from square sliding windows ."
136,"r-cnn, fast, system, two-stage",Fast R-CNN is trained to predict class-specific scores and regress box locations from these sliding windows . We also evaluate using convolutional features extracted from 5 scales .
141,"r-cnn, step, hard-negative, mining, fast, network, sppnet, fine-tuning",We train our models on an 8-GPU implementation . The effective mini-batch size becomes 8 for RPN and 16 for Fast R-CNN . We modify the learning rates because the mini-Batch size is changed . For the anchors we use 3 aspect ratios and 4 scales .
146,"r-cnn, test-dev, fast, map@0.5, set",In Table 11 we first report the results using the implementation in this paper . Our Fast R-CNN baseline has 39.3% mAP@0.5 on the test-dev set .
147,"r-cnn, test-dev, faster, coco, train, to, training, set","Using the COCO training set to train, Faster R-CNN has 42.1% mAP@0.5 . This is 2.8% higher for mPA@0.5 and 21.5% . RPN performs excellent for improving localization accuracy at higher IoU thresholds . Figure 6 shows some results on"
148,"r-cnn, faster, lo, 2015, localization, ilsvrc",Faster R-CNN is a building block of the 1st-place winning entries in ILSVRC 2015 localization and COCO 2015 segmentation competitions . This observation is still valid even when one increases the depth substantially to over 100 layers . Only by replacing VGG-16 with a 101layer residual net
153,"detection, 2007, voc, coco, pascal, test, model, set",COCO is a superset of those on PASCAL VOC . The softmax layer is performed only on the 20 categories plus background . This result is better than that trained on VOC07+12 .
154,"detection, 2007, voc, coco, pascal, model, dataset",Table 6 shows that the model trained on COCO+VOC has the best AP for every individual category on PASCAL VOC 2007 . The extra data from the COCO set increases the mAP by 5.6%.
166,"edge, ijcv, boxes, large-scale, recognition, large-sc, image","J. R. Uijlings, K. E. van de Sande, T. Gevers, and A. W. Smeulders, ""Selective search for object recognition"" in IEEE Conference on Computer Vision and Pattern Recognition ."
167,"semantic, convolutional, networks, segmentation","IEEE Conference on Computer Vision and Pattern Recognition . P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan . Overfeat: Integrated recognition, localization and detection using convolutional networks ."
170,"detection, deep, of, object, learning, residual, model, shapes, sliding, part-based, quality, image","J. Dai, R. Benenson, P. Dollar, and B. Schiele, ""How good are detection proposals, really?"" in British Machine Vision Conference . C. Szegedy, A. Toshev, and D. Anguelov, ""Scalable, high-quality object detection,"""
171,ijcv,"ImageNet Large Scale Visual Recognition Challenge in International Journal of Computer Vision . A. Krizhevsky, I. Sutskever, and G. Hinton, ""Imagenet classification with deep convolutional neural networks"""
